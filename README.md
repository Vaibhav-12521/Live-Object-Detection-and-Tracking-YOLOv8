Hereâ€™s the complete **`README.md`** file content for your GitHub repository:

---

````markdown
# ğŸ¯ Live Object Detection and Tracking using YOLOv8 and OpenCV

This project demonstrates **real-time object detection and tracking** using the **Ultralytics YOLOv8** model integrated with **OpenCV**.  
It captures your webcam feed to identify and track objects with unique IDs and displays FPS on the live video.

---

## ğŸš€ Features

- ğŸ§  Real-time **object detection and tracking**
- ğŸ¥ Live **webcam feed** integration
- âš¡ Displays **FPS (Frames Per Second)** for performance
- ğŸ§­ Unique **object ID tracking**
- ğŸ§± Simple and modular **class-based structure**

---

## ğŸ§° Technologies Used

- **Python 3.8+**
- **OpenCV**
- **NumPy**
- **Ultralytics YOLOv8**

---

## ğŸ“¦ Installation

Clone this repository:
```bash
git clone https://github.com/Vaibhav-12521/Live-Object-Detection-and-Tracking-YOLOv8.git
cd Live-Object-Detection-and-Tracking-YOLOv8
````

Install dependencies:

```bash
pip install opencv-python ultralytics numpy
```

---

## â–¶ï¸ Usage

Run the live object detection:

```bash
python main.py
```

Press **'q'** to quit the window.

---

## ğŸ“‚ Project Structure

```
ğŸ“¦ Live-Object-Detection-and-Tracking-YOLOv8
â”œâ”€â”€ main.py                  # Main script for live detection and tracking
â”œâ”€â”€ yolov8n.pt               # YOLOv8 model file (downloaded automatically if missing)
â”œâ”€â”€ README.md                # Project documentation
â””â”€â”€ requirements.txt         # Required dependencies
```

---

## ğŸ’» Code Overview

```python
from ultralytics import YOLO
import cv2
import numpy as np
from collections import defaultdict

class ObjectdetectTracker:
    def __init__(self, model_path='yolov8n.pt'):
        self.model = YOLO(model_path)
        self.track_history = defaultdict(lambda: [])
        
    def detect_live(self, camera_id=0):
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            return
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            results = self.model.track(frame, persist=True, verbose=False)
            annotated_frame = results[0].plot()
            fps = cap.get(cv2.CAP_PROP_FPS)
            cv2.putText(annotated_frame, f'FPS: {int(fps)}', (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.imshow('Live Object Detection & Tracking', annotated_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        cap.release()
        cv2.destroyAllWindows()
```

---

## ğŸ“¸ Output Preview

|  ğŸ¬ | Description                           |
| :-: | :------------------------------------ |
|  ğŸ§ | Detects multiple objects in real-time |
|  ğŸ§­ | Tracks them with unique IDs           |
|  âš™ï¸ | Displays FPS and bounding boxes       |

---

## ğŸ† Future Enhancements

* ğŸš— Vehicle counting and motion tracking
* ğŸ§ Human pose detection
* ğŸ“Š Object analytics dashboard
* ğŸ’¾ Option to save detection results as video

---

## ğŸ‘¨â€ğŸ’» Author

**Vaibhav Singh**
ğŸ”— [GitHub Profile](https://github.com/Vaibhav-12521)
ğŸ’¬ *If you like this project, give it a â­ on GitHub!*

---


Would you like me to add a **project banner (image + shields badges)** section at the top for a more professional GitHub look?
```
